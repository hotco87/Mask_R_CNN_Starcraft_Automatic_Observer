{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a9189a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy\n",
    "import torch.nn as nn\n",
    "\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "import time\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchsummary import summary\n",
    "\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0ea2f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a0c9409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    model.backbone.body.conv1 = nn.Conv2d(9, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "93656db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_label(path):\n",
    "    replay_name = path.split('/')[-2]\n",
    "    print(\"replay_name:\", replay_name)\n",
    "#     label_path = path.replace(replay_name + \"/\", '')\n",
    "    label_len = len(os.listdir(path))\n",
    "    labels = np.array([])\n",
    "#     print(\"label_path:\",label_path)\n",
    "    for i in range(0, label_len):\n",
    "        labels = np.append(labels, np.load(path +\"/\"+ str(i) + \".npy\", allow_pickle=True)[1])\n",
    "\n",
    "    results = labels\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f9bfb9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PennFudanDataset(object):\n",
    "    def __init__(self, path, transforms, window_size):\n",
    "        self.root = path\n",
    "        self.transforms = transforms\n",
    "        pth = os.listdir(path)\n",
    "        self.label_sequences = []\n",
    "\n",
    "        self.dir_paths = []\n",
    "        if os.path.isdir(path):\n",
    "                self.label_sequences += [load_all_label(path + '/')]\n",
    "                self.dir_paths.append(path +  '/')\n",
    "                print(f\"Loaded {path}\")\n",
    "\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.seq_indexs = []\n",
    "        start = 0\n",
    "        for i, seq in enumerate(self.label_sequences):\n",
    "            end = start + len(seq) - (self.window_size - 1) - 150*(i+1)\n",
    "            self.seq_indexs.append((i, start, end))\n",
    "            start = end\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.seq_indexs[-1][-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        for i, start, end in self.seq_indexs:\n",
    "            if idx >= start and idx < end:\n",
    "                real_idx = idx - start + 150 # *(i+1)\n",
    "\n",
    "                data = np.load(self.dir_paths[i] + '/' + str(real_idx) + \".npy\", allow_pickle=True)[0][0]    # (11, 128, 128)\n",
    "                masks1 = np.load(self.dir_paths[i] + '/' + str(real_idx) + \".npy\", allow_pickle=True)[1][0]   #  (128, 128)\n",
    "                masks2 = np.load(self.dir_paths[i] + '/' + str(real_idx) + \".npy\", allow_pickle=True)[2][0]  # (128, 128)\n",
    "                masks3 = np.load(self.dir_paths[i] + '/' + str(real_idx) + \".npy\", allow_pickle=True)[3][0]  # (128, 128)\n",
    "                masks4 = np.load(self.dir_paths[i] + '/' + str(real_idx) + \".npy\", allow_pickle=True)[4][0]  # (128, 128)\n",
    "                masks5 = np.load(self.dir_paths[i] + '/' + str(real_idx) + \".npy\", allow_pickle=True)[5][0]  # (128, 128)\n",
    "                masks = np.stack((masks1, masks2,masks3,masks4,masks5))\n",
    "\n",
    "                break\n",
    "\n",
    "        input_data = self.preprocessing(data)\n",
    "\n",
    "        num_objs = 5\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        return input_data, target\n",
    "\n",
    "\n",
    "    def preprocessing(self, data):\n",
    "        #0 ground 1 air 2 building 3 spell 4 ground 5 air 6 building 7 spell 8 resource 9 vision 10 terrain\n",
    "        temp = np.zeros([self.window_size, 9, data.shape[2],data.shape[2]])\n",
    "\n",
    "        temp[:,0] = data[0]\n",
    "        temp[:,1] = data[1]\n",
    "        temp[:,2] = data[2]\n",
    "        temp[:,3] = data[4]\n",
    "\n",
    "        temp[:,4] = data[6]\n",
    "        temp[:,5] = data[7]\n",
    "        temp[:,6] = data[8]\n",
    "        temp[:,7] = data[10]\n",
    "\n",
    "        temp[:,8] = data[13]\n",
    "\n",
    "\n",
    "        data = temp\n",
    "        data = data.reshape(self.window_size*data.shape[1],data.shape[2],-1)\n",
    "        # #data = data.reshape(self.window_size*data.shape[0],data.shape[1],-1)\n",
    "        # label = np.array([label[0]/3456, label[1]/3720])\n",
    "        return torch.FloatTensor(data)\n",
    "\n",
    "    # def __len__(self):\n",
    "    #     return len(self.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6e639027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6254\n",
      "36\n",
      "212\n",
      "438\n",
      "522\n",
      "1660\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "data_path = [f\"./testing_data2/6254/6254\", f\"./trainig_data2/36/\",f\"./trainig_data2/212/\",f\"./trainig_data2/438/\",f\"./trainig_data2/522/\",f\"./trainig_data2/1660/\"]\n",
    "for i in data_path:\n",
    "    print(i.split('/')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./testing_data2/6254/6254\n",
      "replay_name: 6254\n",
      "Loaded ./testing_data2/6254/6254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1131it [53:44,  2.89s/it]"
     ]
    }
   ],
   "source": [
    "for i in data_path:\n",
    "    pth = os.listdir(i)    \n",
    "    replay_name = int(i.split('/')[-2])\n",
    "    print(i)\n",
    "    dataset = PennFudanDataset(i, get_transform(train=False), window_size=1)\n",
    "    \n",
    "    dataset_len = len(dataset)\n",
    "    Start, End, Step = 0, len(dataset), 1\n",
    "    test_img_array = []\n",
    "    test_img_one_channel_array = []\n",
    "    test_target_array = []\n",
    "    \n",
    "    num_classes = 2\n",
    "    model = get_model_instance_segmentation(num_classes)\n",
    "    model.load_state_dict(torch.load(\"saved_models/model_29.pth\"))\n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(Start,End,Step):\n",
    "        img_t, target_t = dataset[i]\n",
    "        test_img_array.append(img_t)\n",
    "        img_one_channel = img_t.sum(axis=0, keepdim=True)\n",
    "        test_img_one_channel_array.append(img_one_channel)\n",
    "        test_target_array.append(target_t)\n",
    "        \n",
    "    vpx_array = []\n",
    "    vpy_array = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx,i in tqdm(enumerate(test_img_array)):\n",
    "            prediction = model(torch.unsqueeze(i, 0))\n",
    "            if prediction[0][\"boxes\"].shape[0] == 0:\n",
    "                prediction = model(torch.unsqueeze(i-1, 0))\n",
    "                vpx = int(prediction[0][\"boxes\"][0][1])*32\n",
    "                vpy = int(prediction[0][\"boxes\"][0][0])*32  \n",
    "            else :\n",
    "                vpx = int(prediction[0][\"boxes\"][0][1])*32\n",
    "                vpy = int(prediction[0][\"boxes\"][0][0])*32\n",
    "            vpx_array.append(vpx)\n",
    "            vpy_array.append(vpy)\n",
    "            \n",
    "    # dataset_len = 2000\n",
    "    os.makedirs(\"./saved_xy/\", exist_ok=True)\n",
    "    temp = np.zeros((dataset_len,1))\n",
    "    for i in range (0,dataset_len):\n",
    "        temp[i] = int(i*8)\n",
    "    temp2 = np.zeros((int(temp.max()),1))\n",
    "    for i in range(0, int(temp.max())):\n",
    "        temp2[i] = i\n",
    "\n",
    "    dataset_temp = pd.DataFrame({\"frame\": temp[:,0],\"vpx\": vpx_array[:],\"vpy\": vpy_array[:]})\n",
    "    dataset_temp2 = pd.DataFrame({\"frame\": temp2[:,0]})\n",
    "    dataset = pd.merge(left = dataset_temp2, right = dataset_temp, how= \"left\", on = \"frame\")\n",
    "    dataset = dataset.fillna(method=\"ffill\")\n",
    "    dataset.to_csv(\"./saved_xy/\" + str(replay_name) + \".rep.vpd\", header= True, index=False)\n",
    "    dataset.to_csv(\"C:/TM/starcraft/bwapi-data/read/preset/\" + str(replay_name) + \".rep.vpd\", header= True, index=False)\n",
    "\n",
    "    print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe8531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e59c13f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43eabe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea3b348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded0ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cea3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc34c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2852758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
